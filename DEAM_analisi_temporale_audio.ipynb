{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŽµ Analisi Temporale delle Caratteristiche Audio con Librosa ðŸŽµ\n",
    "\n",
    "Questo notebook si concentra sull'estrazione e visualizzazione delle caratteristiche audio nel tempo, mostrando come le proprietÃ  sonore evolvono durante l'esecuzione di un brano musicale. Analizzeremo come le caratteristiche audio si correlano con le emozioni (arousal e valence) in modo dinamico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparazione dell'ambiente\n",
    "\n",
    "Importiamo le librerie necessarie per l'analisi audio e la visualizzazione dei dati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa  # Libreria principale per l'analisi audio\n",
    "import librosa.display  # Per visualizzare i grafici audio\n",
    "import matplotlib.pyplot as plt  # Per creare grafici\n",
    "import numpy as np  # Per calcoli matematici\n",
    "import pandas as pd  # Per gestire i dati in formato tabellare\n",
    "import seaborn as sns  # Per grafici statistici piÃ¹ avanzati\n",
    "from scipy import stats  # Per calcoli statistici\n",
    "\n",
    "# Impostiamo matplotlib per mostrare grafici piÃ¹ belli\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')  # Utilizziamo uno stile compatibile con le versioni recenti\n",
    "\n",
    "# Impostiamo alcune opzioni di visualizzazione\n",
    "plt.rcParams['figure.figsize'] = (14, 6)  # Dimensione predefinita dei grafici\n",
    "plt.rcParams['font.size'] = 12  # Dimensione del testo nei grafici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Caricamento di un file audio e delle annotazioni emozionali\n",
    "\n",
    "Carichiamo un file audio dal dataset DEAM (Database for Emotional Analysis in Music) e le relative annotazioni dinamiche di arousal e valence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percorso del file audio (da modificare in base alla posizione effettiva)\n",
    "file_path = 'DEAM_audio/esempio.mp3'  # Sostituisci con il percorso del tuo file audio\n",
    "\n",
    "# Carichiamo il file audio\n",
    "# y contiene i dati audio (come un'onda sonora)\n",
    "# sr Ã¨ la frequenza di campionamento (quanti punti al secondo)\n",
    "y, sr = librosa.load(file_path, duration=60)  # Limitiamo a 60 secondi per semplicitÃ \n",
    "\n",
    "print(f\"Durata audio: {len(y)/sr:.2f} secondi\")\n",
    "print(f\"Frequenza di campionamento: {sr} Hz\")\n",
    "\n",
    "# Simuliamo le annotazioni dinamiche di arousal e valence\n",
    "# In un caso reale, queste verrebbero caricate da file\n",
    "# Nota: nel dataset DEAM, le annotazioni sono tipicamente campionate a 2Hz (ogni 500ms)\n",
    "\n",
    "# Creiamo un array di tempo per le annotazioni (un punto ogni 500ms)\n",
    "annotation_time = np.arange(0, len(y)/sr, 0.5)\n",
    "\n",
    "# Simuliamo valori di arousal (eccitazione) che aumentano e diminuiscono nel tempo\n",
    "# In un caso reale, questi dati verrebbero caricati dal dataset DEAM\n",
    "arousal = 0.5 + 0.4 * np.sin(2 * np.pi * annotation_time / 30)\n",
    "\n",
    "# Simuliamo valori di valence (positivitÃ ) che variano nel tempo\n",
    "valence = 0.5 + 0.3 * np.sin(2 * np.pi * annotation_time / 20)\n",
    "\n",
    "# Creiamo un DataFrame per le annotazioni\n",
    "annotations = pd.DataFrame({\n",
    "    'time': annotation_time,\n",
    "    'arousal': arousal,\n",
    "    'valence': valence\n",
    "})\n",
    "\n",
    "print(f\"Numero di annotazioni: {len(annotations)}\")\n",
    "annotations.head()  # Mostriamo le prime righe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualizzazione della forma d'onda e delle annotazioni emozionali\n",
    "\n",
    "Visualizziamo la forma d'onda del brano insieme alle annotazioni di arousal e valence per avere una prima panoramica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creiamo un grafico con 3 sottografici\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(14, 10), sharex=True)\n",
    "\n",
    "# Grafico della forma d'onda\n",
    "librosa.display.waveshow(y, sr=sr, ax=ax1)\n",
    "ax1.set_title('Forma d\\'onda del brano')\n",
    "ax1.set_ylabel('Ampiezza')\n",
    "\n",
    "# Grafico dell'arousal nel tempo\n",
    "ax2.plot(annotations['time'], annotations['arousal'], color='red')\n",
    "ax2.set_title('Arousal (eccitazione) nel tempo')\n",
    "ax2.set_ylabel('Arousal (0-1)')\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.grid(True)\n",
    "\n",
    "# Grafico della valence nel tempo\n",
    "ax3.plot(annotations['time'], annotations['valence'], color='green')\n",
    "ax3.set_title('Valence (positivitÃ ) nel tempo')\n",
    "ax3.set_xlabel('Tempo (secondi)')\n",
    "ax3.set_ylabel('Valence (0-1)')\n",
    "ax3.set_ylim(0, 1)\n",
    "ax3.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Estrazione delle caratteristiche audio nel tempo\n",
    "\n",
    "Ora estraiamo diverse caratteristiche audio e le analizziamo nel tempo, utilizzando finestre temporali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiamo la dimensione della finestra per l'analisi temporale (in campioni)\n",
    "# Utilizziamo una finestra di 0.5 secondi per allinearci con le annotazioni\n",
    "frame_length = int(sr * 0.5)  # 0.5 secondi di audio\n",
    "hop_length = frame_length  # Non sovrapponiamo le finestre per semplicitÃ \n",
    "\n",
    "# Calcoliamo il numero di frame che otterremo\n",
    "n_frames = 1 + int((len(y) - frame_length) / hop_length)\n",
    "print(f\"Numero di frame temporali: {n_frames}\")\n",
    "\n",
    "# Creiamo array vuoti per memorizzare le caratteristiche estratte\n",
    "frame_times = []  # Tempo centrale di ogni frame\n",
    "rms_values = []  # Root Mean Square (energia)\n",
    "spectral_centroid_values = []  # Centroide spettrale (brillantezza)\n",
    "spectral_contrast_values = []  # Contrasto spettrale (differenza tra picchi e valli)\n",
    "spectral_rolloff_values = []  # Rolloff spettrale (distribuzione dell'energia)\n",
    "\n",
    "# Estraiamo le caratteristiche frame per frame\n",
    "for i in range(n_frames):\n",
    "    # Calcoliamo l'indice di inizio e fine del frame corrente\n",
    "    start = i * hop_length\n",
    "    end = min(start + frame_length, len(y))\n",
    "    \n",
    "    # Estraiamo il segmento audio per questo frame\n",
    "    frame = y[start:end]\n",
    "    \n",
    "    # Calcoliamo il tempo centrale di questo frame (in secondi)\n",
    "    frame_time = (start + (end - start) / 2) / sr\n",
    "    frame_times.append(frame_time)\n",
    "    \n",
    "    # Energia (RMS) - correlata all'intensitÃ /volume\n",
    "    rms = np.sqrt(np.mean(frame**2))\n",
    "    rms_values.append(rms)\n",
    "    \n",
    "    # Se il frame Ã¨ troppo corto, alcune funzioni potrebbero fallire\n",
    "    # Aggiungiamo controlli per evitare errori\n",
    "    if len(frame) > 0:\n",
    "        # Centroide spettrale - correlato alla brillantezza/acutezza\n",
    "        centroid = np.mean(librosa.feature.spectral_centroid(y=frame, sr=sr))\n",
    "        spectral_centroid_values.append(centroid)\n",
    "        \n",
    "        # Contrasto spettrale - correlato alla differenza tra picchi e valli\n",
    "        contrast = np.mean(librosa.feature.spectral_contrast(y=frame, sr=sr))\n",
    "        spectral_contrast_values.append(contrast)\n",
    "        \n",
    "        # Rolloff spettrale - correlato alla distribuzione dell'energia\n",
    "        rolloff = np.mean(librosa.feature.spectral_rolloff(y=frame, sr=sr))\n",
    "        spectral_rolloff_values.append(rolloff)\n",
    "    else:\n",
    "        # Se il frame Ã¨ vuoto, aggiungiamo valori nulli\n",
    "        spectral_centroid_values.append(0)\n",
    "        spectral_contrast_values.append(0)\n",
    "        spectral_rolloff_values.append(0)\n",
    "\n",
    "# Creiamo un DataFrame con tutte le caratteristiche estratte\n",
    "features_df = pd.DataFrame({\n",
    "    'time': frame_times,\n",
    "    'rms': rms_values,\n",
    "    'spectral_centroid': spectral_centroid_values,\n",
    "    'spectral_contrast': spectral_contrast_values,\n",
    "    'spectral_rolloff': spectral_rolloff_values\n",
    "})\n",
    "\n",
    "# Normalizziamo i valori per una migliore visualizzazione\n",
    "for col in ['rms', 'spectral_centroid', 'spectral_contrast', 'spectral_rolloff']:\n",
    "    if features_df[col].max() > 0:  # Evitiamo divisione per zero\n",
    "        features_df[col] = features_df[col] / features_df[col].max()\n",
    "\n",
    "features_df.head()  # Mostriamo le prime righe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Estrazione di MFCC e Chroma nel tempo\n",
    "\n",
    "Estraiamo anche i coefficienti MFCC (Mel-Frequency Cepstral Coefficients) e le caratteristiche Chroma, che sono particolarmente utili per l'analisi delle emozioni nella musica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estraiamo i MFCC (caratteristiche timbriche)\n",
    "# Utilizziamo hop_length uguale a frame_length per allinearci con le altre caratteristiche\n",
    "mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13, hop_length=hop_length)\n",
    "\n",
    "# Estraiamo le caratteristiche Chroma (contenuto armonico)\n",
    "chroma = librosa.feature.chroma_stft(y=y, sr=sr, hop_length=hop_length)\n",
    "\n",
    "# Per ogni frame, calcoliamo la media dei coefficienti MFCC e Chroma\n",
    "# Questo ci dÃ  un valore singolo per frame, piÃ¹ facile da visualizzare\n",
    "mfcc_means = np.mean(mfccs, axis=0)\n",
    "chroma_means = np.mean(chroma, axis=0)\n",
    "\n",
    "# Aggiungiamo questi valori al nostro DataFrame\n",
    "# Assicuriamoci che le lunghezze corrispondano\n",
    "min_length = min(len(features_df), len(mfcc_means), len(chroma_means))\n",
    "features_df = features_df.iloc[:min_length].copy()\n",
    "features_df['mfcc_mean'] = mfcc_means[:min_length]\n",
    "features_df['chroma_mean'] = chroma_means[:min_length]\n",
    "\n",
    "# Normalizziamo anche questi valori\n",
    "for col in ['mfcc_mean', 'chroma_mean']:\n",
    "    if features_df[col].max() > 0:  # Evitiamo divisione per zero\n",
    "        features_df[col] = features_df[col] / features_df[col].max()\n",
    "\n",
    "features_df.head()  # Mostriamo le prime righe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualizzazione dell'evoluzione delle caratteristiche nel tempo\n",
    "\n",
    "Ora visualizziamo come le caratteristiche audio estratte evolvono nel tempo durante il brano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creiamo un grafico con piÃ¹ sottografici\n",
    "fig, axes = plt.subplots(6, 1, figsize=(14, 16), sharex=True)\n",
    "\n",
    "# Grafico della forma d'onda\n",
    "librosa.display.waveshow(y, sr=sr, ax=axes[0])\n",
    "axes[0].set_title('Forma d\\'onda')\n",
    "axes[0].set_ylabel('Ampiezza')\n",
    "\n",
    "# Grafico dell'energia (RMS)\n",
    "axes[1].plot(features_df['time'], features_df['rms'], color='purple')\n",
    "axes[1].set_title('Energia (RMS)')\n",
    "axes[1].set_ylabel('Valore norm.')\n",
    "axes[1].grid(True)\n",
    "\n",
    "# Grafico del centroide spettrale\n",
    "axes[2].plot(features_df['time'], features_df['spectral_centroid'], color='blue')\n",
    "axes[2].set_title('Centroide Spettrale (brillantezza)')\n",
    "axes[2].set_ylabel('Valore norm.')\n",
    "axes[2].grid(True)\n",
    "\n",
    "# Grafico del contrasto spettrale\n",
    "axes[3].plot(features_df['time'], features_df['spectral_contrast'], color='orange')\n",
    "axes[3].set_title('Contrasto Spettrale')\n",
    "axes[3].set_ylabel('Valore norm.')\n",
    "axes[3].grid(True)\n",
    "\n",
    "# Grafico della media dei MFCC\n",
    "axes[4].plot(features_df['time'], features_df['mfcc_mean'], color='green')\n",
    "axes[4].set_title('Media dei coefficienti MFCC (timbro)')\n",
    "axes[4].set_ylabel('Valore norm.')\n",
    "axes[4].grid(True)\n",
    "\n",
    "# Grafico della media dei Chroma\n",
    "axes[5].plot(features_df['time'], features_df['chroma_mean'], color='red')\n",
    "axes[5].set_title('Media dei valori Chroma (contenuto armonico)')\n",
    "axes[5].set_xlabel('Tempo (secondi)')\n",
    "axes[5].set_ylabel('Valore norm.')\n",
    "axes[5].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Confronto con le annotazioni emozionali\n",
    "\n",
    "Ora confrontiamo l'evoluzione delle caratteristiche audio con le annotazioni di arousal e valence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniamo il DataFrame delle caratteristiche con quello delle annotazioni\n",
    "# Utilizziamo un'interpolazione per allineare i tempi\n",
    "\n",
    "# Creiamo una funzione per interpolare i valori di arousal e valence\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# Creiamo funzioni di interpolazione\n",
    "arousal_interp = interp1d(annotations['time'], annotations['arousal'], \n",
    "                         bounds_error=False, fill_value='extrapolate')\n",
    "valence_interp = interp1d(annotations['time'], annotations['valence'], \n",
    "                         bounds_error=False, fill_value='extrapolate')\n",
    "\n",
    "# Applichiamo l'interpolazione ai tempi delle caratteristiche\n",
    "features_df['arousal'] = arousal_interp(features_df['time'])\n",
    "features_df['valence'] = valence_interp(features_df['time'])\n",
    "\n",
    "# Visualizziamo le caratteristiche insieme alle annotazioni\n",
    "fig, axes = plt.subplots(4, 1, figsize=(14, 14), sharex=True)\n",
    "\n",
    "# Grafico dell'arousal\n",
    "axes[0].plot(features_df['time'], features_df['arousal'], color='red', linewidth=2)\n",
    "axes[0].set_title('Arousal (eccitazione)')\n",
    "axes[0].set_ylabel('Valore (0-1)')\n",
    "axes[0].set_ylim(0, 1)\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Grafico della valence\n",
    "axes[1].plot(features_df['time'], features_df['valence'], color='green', linewidth=2)\n",
    "axes[1].set_title('Valence (positivitÃ )')\n",
    "axes[1].set_ylabel('Valore (0-1)')\n",
    "axes[1].set_ylim(0, 1)\n",
    "axes[1].grid(True)\n",
    "\n",
    "# Grafico dell'energia (RMS) - spesso correlata all'arousal\n",
    "axes[2].plot(features_df['time'], features_df['rms'], color='purple')\n",
    "axes[2].set_title('Energia (RMS) - spesso correlata con Arousal')\n",
    "axes[2].set_ylabel('Valore norm.')\n",
    "axes[2].grid(True)\n",
    "\n",
    "# Grafico del contrasto spettrale - spesso correlato alla valence\n",
    "axes[3].plot(features_df['time'], features_df['spectral_contrast'], color='orange')\n",
    "axes[3].set_title('Contrasto Spettrale - spesso correlato con Valence')\n",
    "axes[3].set_xlabel('Tempo (secondi)')\n",
    "axes[3].set_ylabel('Valore norm.')\n",
    "axes[3].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Analisi della correlazione dinamica\n",
    "\n",
    "Calcoliamo la correlazione tra le caratteristiche audio e le annotazioni emozionali nel tempo, utilizzando una finestra mobile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiamo una funzione per calcolare la correlazione in una finestra mobile\n",
    "def rolling_correlation(df, feature, emotion, window_size=10):\n",
    "    # Creiamo array per memorizzare i risultati\n",
    "    times = []\n",
    "    correlations = []\n",
    "    \n",
    "    # Verifichiamo che la dimensione della finestra sia valida\n",
    "    if window_size >= len(df):\n",
    "        window_size = max(2, len(df) // 2)  # Impostiamo una dimensione ragionevole\n",
    "        print(f\"Dimensione finestra troppo grande, ridotta a {window_size}\")\n",
    "    \n",
    "    # Verifichiamo che ci siano abbastanza dati per calcolare la correlazione\n",
    "    if len(df) < 2:\n",
    "        print(\"Non ci sono abbastanza dati per calcolare la correlazione\")\n",
    "        return [], []\n",
    "    \n",
    "    # Calcoliamo la correlazione per ogni finestra\n",
    "    for i in range(len(df) - window_size + 1):\n",
    "        # Estraiamo la finestra corrente\n",
    "        window = df.iloc[i:i+window_size]\n",
    "        \n",
    "        # Verifichiamo che non ci siano valori NaN\n",
    "        if window[feature].isna().any() or window[emotion].isna().any():\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Calcoliamo la correlazione di Pearson\n",
    "            # Verifichiamo che ci sia varianza nei dati\n",
    "            if window[feature].std() > 0 and window[emotion].std() > 0:\n",
    "                corr, _ = stats.pearsonr(window[feature], window[emotion])\n",
    "                \n",
    "                # Memorizziamo il tempo centrale della finestra e la correlazione\n",
    "                times.append(window['time'].mean())\n",
    "                correlations.append(corr)\n",
    "            else:\n",
    "                # Se non c'Ã¨ varianza, la correlazione Ã¨ indefinita\n",
    "                times.append(window['time'].mean())\n",
    "                correlations.append(0)  # Impostiamo a zero per convenzione\n",
    "        except Exception as e:\n",
    "            print(f\"Errore nel calcolo della correlazione: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return times, correlations\n",
    "\n",
    "# Calcoliamo la correlazione mobile tra RMS e arousal\n",
    "rms_arousal_times, rms_arousal_corrs = rolling_correlation(features_df, 'rms', 'arousal', window_size=10)\n",
    "\n",
    "# Calcoliamo la correlazione mobile tra contrasto spettrale e valence\n",
    "contrast_valence_times, contrast_valence_corrs = rolling_correlation(features_df, 'spectral_contrast', 'valence', window_size=10)\n",
    "\n",
    "# Verifichiamo che ci siano dati da visual